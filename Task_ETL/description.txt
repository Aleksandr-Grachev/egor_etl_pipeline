1 задание было сделано в 3 вариантах


1 - с помощью дага airflow, изначально, в "stage" ветку вставляются сырые данные, после этого данные обрабатываются,
    удаляются дубли, данные приводятся к нормальному типу и переносятся с помощью sql скриптов в ветку "DS"

    UPDATE стратегия такова, изначально данные пытаются обновиться если совпадают PK с уже имеющимися данными в схеме "DS",
    после этого идёт вставка УНИКАЛЬНЫХ данных (значения PK еще не существует) 

2 - так же с помощью дага, но sql скрипты выполняются в самом DAG'e, а так же данные сразу помещаются в ветку "DS"
    с предварительной обработкой, по сравнению с 1 способом данные загружаются медленнее

    UPDATE стратегия этого способа немного отличается, используется вставка информации, но при конфликте(ON CONFLICT) с PK,
    выполняется обновление конфликтных строк

3 - с помощью обычного .py скрипта, данные так же сразу помещаются в ветку "DS" после обработки
    Перед тем как выполнить UPDATE, код сначала проверяет, существует ли уже строка с таким PK
    Если строка существует, выполняется обновление, если нет, то вставка

    